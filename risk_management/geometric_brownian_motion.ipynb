{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb3iHRpj_bBs"
   },
   "source": [
    "# Simulating Geometric Brownian Motion (GBM) in Python\n",
    "\n",
    "Geometric Brownian motion (GBM) S is defined by S0 > 0 and the dynamics as defined in the following Stochastic Differential Equation (SDE):\n",
    "\n",
    "\n",
    "$\\Large dS_t = \\mu S_t dt + \\sigma S_t dW_t$\n",
    "\n",
    "Integrated Form:\n",
    "\n",
    " - $\\log S_t = \\log S_0 + \\int_{0}^{t} (\\mu-\\frac{\\sigma^2}{2}) \\,ds + \\int_{0}^{t} \\sigma \\,dW_s $\n",
    "\n",
    " - $\\log S_t = \\log S_0 + (\\mu-\\frac{\\sigma^2}{2})t + \\sigma W_t $\n",
    "\n",
    " - $\\log S_t \\sim N(\\log S_0 + (\\mu-\\frac{\\sigma^2}{2})t, \\sigma^2 t)$\n",
    "\n",
    "Explicit Expression:\n",
    "\n",
    "$\\Large S_t = S_0 {\\rm e}^{(\\mu-\\frac{\\sigma^2}{2})t + \\sigma W_t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMf9KxZp_bBx"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkRyxFT5_bBy"
   },
   "source": [
    "### Simulating GBM Paths\n",
    "\n",
    "We have two options here, we can either:\n",
    "- (like here) simulate the stock price directly throughout the simulation and multiple the exponential terms together at each time step; or\n",
    "- we can simulate the log normal distribution and cumulatively add the terms along each sample path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\Large S_t = S_0 {\\rm e}^{(\\mu-\\frac{\\sigma^2}{2})t + \\sigma W_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_1 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 1.csv')\n",
    "database_2 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 2.csv')\n",
    "database_3 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 3.csv')\n",
    "database_4 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 4.csv')\n",
    "database_5 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 5.csv')\n",
    "database_6 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 6.csv')\n",
    "database_7 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 7.csv')\n",
    "database_8 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 8.csv')\n",
    "database_9 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 9.csv')\n",
    "database_10 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 10.csv')\n",
    "database_11 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 11.csv')\n",
    "database_12 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 12.csv')\n",
    "database_13 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 13.csv')\n",
    "database_14 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 14.csv')\n",
    "database_15 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 15.csv')\n",
    "database_16 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 16.csv')\n",
    "database_17 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 17.csv')\n",
    "database_18 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 18.csv')\n",
    "database_19 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 19.csv')\n",
    "database_20 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 20.csv')\n",
    "database_21 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 21.csv')\n",
    "database_22 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 22.csv')\n",
    "database_23 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 23.csv')\n",
    "database_24 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 24.csv')\n",
    "database_25 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 25.csv')\n",
    "database_26 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 26.csv')\n",
    "database_27 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 27.csv')\n",
    "database_28 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 28.csv')\n",
    "database_29 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 29.csv')\n",
    "database_30 = pd.read_csv('c:\\\\Users\\\\Infovesta PC-57\\\\quanti-trading-plan\\\\data\\\\database_daily_update\\\\Database Part 30.csv')\n",
    "database = pd.concat([database_1,database_2,database_3,database_4,database_5,database_6,database_7,database_8,database_9,database_10,\n",
    "                      database_11,database_12,database_13,database_14,database_15,database_16,database_17,database_18,database_19,database_20,\n",
    "                      database_21,database_22,database_23,database_24,database_25,database_26,database_27,database_28,database_29,database_30])\n",
    "database = database.drop(columns='Unnamed: 0')\n",
    "#Substitusi nilai Open, High, Low Price yg 0 dengan Close Price\n",
    "database['Open Price'] = np.where(database['Open Price'].eq(0),database['Close Price'],database['Open Price'])\n",
    "database['High Price'] = np.where(database['High Price'].eq(0),database['Close Price'],database['High Price'])\n",
    "database['Low Price'] = np.where(database['Low Price'].eq(0),database['Close Price'],database['Low Price'])\n",
    "df = database[['Kode','Date','Close Price']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data,stock, date, period):\n",
    "    data = data[data['Kode']==stock]\n",
    "    data = data.sort_values(by='Date')\n",
    "    data_selected = data[data['Date']<=date]\n",
    "    data_selected = data_selected.tail(period)\n",
    "    prices = data_selected['Close Price'].values\n",
    "    logprices = np.log(prices)\n",
    "    logreturns = logprices[1:] - logprices[:-1]\n",
    "    mu = np.mean(logreturns)\n",
    "    sigma = np.std(logreturns)\n",
    "    return data,data_selected, mu, sigma\n",
    "            \n",
    "def simulate_1d_gbm(nsteps, mu, sigma, ref_price):\n",
    "    steps = [ (mu - (sigma**2)/2) + np.random.randn()*sigma for i in range(nsteps-1) ]\n",
    "    steps.insert(0,0)\n",
    "    res = ref_price*np.exp(np.cumsum(steps))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is 0.0004027733739895166, stdev is 0.024860706056819223\n",
      "Ref price: 312.0\n",
      "Expected end price: 320.01227445484614\n",
      "Actual end price: 308.0\n",
      "Bottom price at 1% probability: 198.49373739067215\n",
      "Bottom price at 2% probability: 209.71505145868989\n",
      "Bottom price at 5% probability: 227.27616339180744\n",
      "Bottom price at 10% probability: 243.98658262665106\n"
     ]
    }
   ],
   "source": [
    "param_period = 252 #param_period adalah periode pengambilan mu dan sigma, pred_period adalah holding period indeks. dibedakan karena mengurangi efek seasonality. contoh: jika param_period = pred_period = 63 maka seasonality terjadi karena momentum sering berbalik arah tiap 3 bulan\n",
    "pred_period = 63\n",
    "stock = 'ELSA'\n",
    "sim_num = 100000\n",
    "date = '2023-01-04'\n",
    "\n",
    "data,data_selected,mu, sigma = data_preprocessing(data=df,stock=stock, date=date, period=param_period)\n",
    "ref_price = data[data['Date']==date]['Close Price'].iloc[0]\n",
    "y_list = []\n",
    "for i in list(range(0,sim_num)):\n",
    "    y = simulate_1d_gbm(nsteps=param_period, mu=mu, sigma=sigma, ref_price=ref_price)\n",
    "    y_list.append(y[pred_period])   #Ubah prediction period disini\n",
    "\n",
    "exp_price = np.mean(y_list)\n",
    "date_list = list(data['Date'])\n",
    "date_i = date_list.index(date) + pred_period\n",
    "date_ = date_list[date_i]\n",
    "act_price = data[data['Date']==date_]['Close Price'].iloc[0]\n",
    "print(f'Mean is {mu}, stdev is {sigma}')\n",
    "print(f'Ref price: {ref_price}')\n",
    "print(f'Expected end price: {exp_price}')\n",
    "print(f'Actual end price: {act_price}')\n",
    "for i in [1,2,5,10]:\n",
    "    threshold = np.percentile(y_list, i)\n",
    "    print(f'Bottom price at {i}% probability: {threshold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [120, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "lower_threshold = np.percentile(list_, 5)\n",
    "upper_threshold = np.percentile(list_, 95)\n",
    "\n",
    "#bottom_5_percent = [x for x in data if x <= lower_threshold]\n",
    "#top_5_percent = [x for x in data if x >= upper_threshold]\n",
    "\n",
    "#print(\"Bottom 5% values:\", bottom_5_percent)\n",
    "#print(\"Top 5% values:\", top_5_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(24.5), np.float64(110.99999999999997))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_threshold, upper_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
